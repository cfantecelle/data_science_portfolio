{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sC2BFMOKN1M7"
      },
      "source": [
        "---\n",
        "<img alt=\"Colaboratory logo\" width=\"15%\" src=\"https://raw.githubusercontent.com/carlosfab/escola-data-science/master/img/novo_logo_bg_claro.png\">\n",
        "\n",
        "#### **Data Science na Pr√°tica 3.0**\n",
        "*by [sigmoidal.ai](https://sigmoidal.ai)*  \n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IR56trFcPcC1"
      },
      "source": [
        "# Credit Card fraud detection\n",
        "\n",
        "In the current project, we will address the issue of credit card frauds, which is considered to be a form of identity theft. Typically, this type of fraud occurs from the illegal charging of purchases or funds removal from another's account due to unauthorised use of the person's credit card information<sup><a href=\"https://www.law.cornell.edu/wex/credit_card_fraud\">1</a></sup>. This type of fraud is a major cause of concern in financial institutions and fintechs globally. According to the Nilson Report, credit card fraud worldwide led to the loss of $28.58 billion in 2020<sup><a href=\"https://nilsonreport.com/mention/1515/1link/\">2</a></sup>.\n",
        "\n",
        "<p align=center>\n",
        "<img src=\"img/cctheft.jpg\" width=\"50%\"><br>\n",
        "<i><sup>Image credits: kjpargeter (<a href=\"https://www.freepik.com/search?author=938508&authorSlug=kjpargeter&format=author&selection=1\">www.freepik.com</a>)</sup></i>\n",
        "</p>\n",
        "\n",
        "Thus, credit card frauds are greatly relevant due to their potential to considerably harm both costumers and financial institutions. Another factor to be taken into account are the action to preventively block a credit card due to suspicious activity. If the transaction is genuine, this causes both stress and embarassment to the clients who are denied their purchase.\n",
        "\n",
        "For the aforementioned reasons, investments in Fraud Detection through Artificial Inteligence are increasing constantly, presenting as a great Data Science oportunity. Slightly better machine learning algorithms, with great volumes of data as a base, already represent millions in economy through fraud avoidance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HVmpIxQWT4Y"
      },
      "source": [
        "## Getting the data\n",
        "\n",
        "The data that we are using in this project is available on the [Kaggle](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud) website. It consists of anonymized credit card transactions, which were labeled as fraudulent or genuine transactions. \n",
        "\n",
        "The dataset actually consists of credit card transactions registered in September 2013 by cardholders in Europe. It represents transactions made over the course of two days, where **492 frauds** were identified, out of 284,807 transactions. In total, the operations marked as fraudulent represent only 0.172% of the total dataset, making this dataset highly unbalanced<sup><a href=\"https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud\">3</a></sup>.\n",
        "\n",
        "<p align=center>\n",
        "<img src=\"img/ccpayment.jpg\" width=\"50%\"><br>\n",
        "<i><sup>Image credits: freepik (<a href=\"https://www.freepik.com/free-photo/person-paying-with-its-credit-card_20083164.htm\">www.freepik.com</a>)</sup></i>\n",
        "</p>\n",
        "\n",
        "In addition, the source informs that the dataset has been through a dimensionality reduction transformation: the Principal Component Analysis (PCA). This was done to protect user identities and other sensitive features in the dataset, while also reducing its complexity.\n",
        "\n",
        "With the increase in the number of variables in a given dataset, the difficulty to visualize a multi-dimensional hyperspace also increases. The goal of the PCA is to extract important information from this multi-variate data that are inter-correlated. While each variable is considered a different *dimension*, the PCA extracts the information in the dataset as a set of new variables called **principal components**, reducing the number of *dimensions* from the original dataset. These **principal components** correspond to a linear combination of the original variables and their goal is to encapsulate most of the variation present in the dataset<sup><a href=\"http://www.sthda.com/english/articles/31-principal-component-methods-in-r-practical-guide/112-pca-principal-component-analysis-essentials/\">4</a></sup>.\n",
        "\n",
        "In our dataset, the **principal components** correspond to the columns in the dataset: $[V1, V2, V3 \\dots, Vn]$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Loading necessary packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Importing packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import scikitplot as skplt\n",
        "\n",
        "from scipy import stats\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5XDTWW5LRVe"
      },
      "source": [
        "### Importing the data\n",
        "\n",
        "For ease of access, since this is a bigger file, we will import it as a direct access link."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "4NxUOfDOj2j8"
      },
      "outputs": [],
      "source": [
        "file_path = \"https://onedrive.live.com/download?cid=A06C4A8AAF3A347B&resid=A06C4A8AAF3A347B%215208&authkey=AAdhamfzp5RS9PM\"\n",
        "\n",
        "# Downloading and reading the file\n",
        "df = pd.read_csv(file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, let's verify basic characteristics of our dataset and subset the `test` data that is going to be used later on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original size of the dataset:  174907  entries.\n",
            "Test dataset size:  26236  entries.\n",
            "Remaining dataset size:  148671  entries.\n"
          ]
        }
      ],
      "source": [
        "# Original size\n",
        "print('Original size of the dataset: ', df.shape[0], ' entries.')\n",
        "\n",
        "# Separating test data\n",
        "test = df.sample(frac=0.15, random_state=42)\n",
        "\n",
        "# Removing test data from regular df\n",
        "df = df.drop(test.index)\n",
        "\n",
        "# Test dataset size\n",
        "print('Test dataset size: ', test.shape[0], ' entries.')\n",
        "print('Remaining dataset size: ', df.shape[0], ' entries.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nF_Dhd81Cvq"
      },
      "source": [
        "Having imported the data, we can begin the exploratory analysis of the dataset while also preparing the data to use in a **machine learning** model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UtXyZ6stlSM"
      },
      "source": [
        "## Exploratory analysis\n",
        "\n",
        "To begin our analysis, let us look a the first entries of the dataframe:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>...</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>...</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>378.66</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>123.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.0</td>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.009431</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>69.99</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7.0</td>\n",
              "      <td>-0.644269</td>\n",
              "      <td>1.417964</td>\n",
              "      <td>1.074380</td>\n",
              "      <td>-0.492199</td>\n",
              "      <td>0.948934</td>\n",
              "      <td>0.428118</td>\n",
              "      <td>1.120631</td>\n",
              "      <td>-3.807864</td>\n",
              "      <td>0.615375</td>\n",
              "      <td>...</td>\n",
              "      <td>1.943465</td>\n",
              "      <td>-1.015455</td>\n",
              "      <td>0.057504</td>\n",
              "      <td>-0.649709</td>\n",
              "      <td>-0.415267</td>\n",
              "      <td>-0.051634</td>\n",
              "      <td>-1.206921</td>\n",
              "      <td>-1.085339</td>\n",
              "      <td>40.80</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>10.0</td>\n",
              "      <td>1.449044</td>\n",
              "      <td>-1.176339</td>\n",
              "      <td>0.913860</td>\n",
              "      <td>-1.375667</td>\n",
              "      <td>-1.971383</td>\n",
              "      <td>-0.629152</td>\n",
              "      <td>-1.423236</td>\n",
              "      <td>0.048456</td>\n",
              "      <td>-1.720408</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.009302</td>\n",
              "      <td>0.313894</td>\n",
              "      <td>0.027740</td>\n",
              "      <td>0.500512</td>\n",
              "      <td>0.251367</td>\n",
              "      <td>-0.129478</td>\n",
              "      <td>0.042850</td>\n",
              "      <td>0.016253</td>\n",
              "      <td>7.80</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows √ó 31 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    Time        V1        V2        V3        V4        V5        V6  \\\n",
              "2    1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499   \n",
              "3    1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203   \n",
              "4    2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921   \n",
              "7    7.0 -0.644269  1.417964  1.074380 -0.492199  0.948934  0.428118   \n",
              "10  10.0  1.449044 -1.176339  0.913860 -1.375667 -1.971383 -0.629152   \n",
              "\n",
              "          V7        V8        V9  ...       V21       V22       V23       V24  \\\n",
              "2   0.791461  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281   \n",
              "3   0.237609  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575   \n",
              "4   0.592941 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267   \n",
              "7   1.120631 -3.807864  0.615375  ...  1.943465 -1.015455  0.057504 -0.649709   \n",
              "10 -1.423236  0.048456 -1.720408  ... -0.009302  0.313894  0.027740  0.500512   \n",
              "\n",
              "         V25       V26       V27       V28  Amount  Class  \n",
              "2  -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
              "3   0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
              "4  -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
              "7  -0.415267 -0.051634 -1.206921 -1.085339   40.80      0  \n",
              "10  0.251367 -0.129478  0.042850  0.016253    7.80      0  \n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "From this initial look, we can see that our data is entirely numeric after the dimensionality reduction (the *Principal Component Analysis*). Follow [this link](https://builtin.com/data-science/step-step-explanation-principal-component-analysis) if you want to know more about the method.\n",
        "\n",
        "The only values that were preserved were the columns:\n",
        "* `Time`: Number of seconds elapsed between this transaction and the first transaction in the dataset;\n",
        "* `Amount`: Value that represents the transaction amount;\n",
        "* `Class`: Binary coded variable, with '1' representing fraudulent transactions and '0' representing regular ones.\n",
        "\n",
        "Now, let us do descriptive statistics on the dataset and check if there are any missing values:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>...</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>148671.000000</td>\n",
              "      <td>148671.000000</td>\n",
              "      <td>148671.000000</td>\n",
              "      <td>148671.000000</td>\n",
              "      <td>148671.000000</td>\n",
              "      <td>148671.000000</td>\n",
              "      <td>148671.000000</td>\n",
              "      <td>148671.000000</td>\n",
              "      <td>148671.000000</td>\n",
              "      <td>148671.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>148671.000000</td>\n",
              "      <td>148671.000000</td>\n",
              "      <td>148671.000000</td>\n",
              "      <td>148671.000000</td>\n",
              "      <td>148671.000000</td>\n",
              "      <td>148671.000000</td>\n",
              "      <td>148671.000000</td>\n",
              "      <td>148671.000000</td>\n",
              "      <td>148671.000000</td>\n",
              "      <td>148671.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>94665.917819</td>\n",
              "      <td>0.001213</td>\n",
              "      <td>-0.003787</td>\n",
              "      <td>0.000954</td>\n",
              "      <td>0.000726</td>\n",
              "      <td>-0.000325</td>\n",
              "      <td>0.000314</td>\n",
              "      <td>0.001003</td>\n",
              "      <td>0.001141</td>\n",
              "      <td>0.002966</td>\n",
              "      <td>...</td>\n",
              "      <td>0.002433</td>\n",
              "      <td>-0.000928</td>\n",
              "      <td>-0.000682</td>\n",
              "      <td>0.000927</td>\n",
              "      <td>-0.000814</td>\n",
              "      <td>-0.000461</td>\n",
              "      <td>-0.001375</td>\n",
              "      <td>0.000457</td>\n",
              "      <td>88.940157</td>\n",
              "      <td>0.001762</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>47491.905807</td>\n",
              "      <td>1.952630</td>\n",
              "      <td>1.652412</td>\n",
              "      <td>1.504227</td>\n",
              "      <td>1.412236</td>\n",
              "      <td>1.396980</td>\n",
              "      <td>1.342388</td>\n",
              "      <td>1.243926</td>\n",
              "      <td>1.175264</td>\n",
              "      <td>1.096171</td>\n",
              "      <td>...</td>\n",
              "      <td>0.728833</td>\n",
              "      <td>0.725047</td>\n",
              "      <td>0.628792</td>\n",
              "      <td>0.605060</td>\n",
              "      <td>0.521639</td>\n",
              "      <td>0.483091</td>\n",
              "      <td>0.408883</td>\n",
              "      <td>0.334947</td>\n",
              "      <td>255.996600</td>\n",
              "      <td>0.041943</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>-56.407510</td>\n",
              "      <td>-72.715728</td>\n",
              "      <td>-48.325589</td>\n",
              "      <td>-5.401678</td>\n",
              "      <td>-113.743307</td>\n",
              "      <td>-26.160506</td>\n",
              "      <td>-31.197329</td>\n",
              "      <td>-50.943369</td>\n",
              "      <td>-9.481456</td>\n",
              "      <td>...</td>\n",
              "      <td>-22.757540</td>\n",
              "      <td>-10.933144</td>\n",
              "      <td>-44.807735</td>\n",
              "      <td>-2.836627</td>\n",
              "      <td>-10.295397</td>\n",
              "      <td>-2.534330</td>\n",
              "      <td>-9.895244</td>\n",
              "      <td>-15.430084</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>54063.000000</td>\n",
              "      <td>-0.919470</td>\n",
              "      <td>-0.595982</td>\n",
              "      <td>-0.889173</td>\n",
              "      <td>-0.845732</td>\n",
              "      <td>-0.689837</td>\n",
              "      <td>-0.767787</td>\n",
              "      <td>-0.552822</td>\n",
              "      <td>-0.208169</td>\n",
              "      <td>-0.640412</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.227944</td>\n",
              "      <td>-0.543619</td>\n",
              "      <td>-0.161469</td>\n",
              "      <td>-0.353986</td>\n",
              "      <td>-0.317920</td>\n",
              "      <td>-0.327894</td>\n",
              "      <td>-0.071149</td>\n",
              "      <td>-0.052876</td>\n",
              "      <td>5.600000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>84637.000000</td>\n",
              "      <td>0.017236</td>\n",
              "      <td>0.064909</td>\n",
              "      <td>0.179942</td>\n",
              "      <td>-0.017119</td>\n",
              "      <td>-0.053146</td>\n",
              "      <td>-0.275032</td>\n",
              "      <td>0.039402</td>\n",
              "      <td>0.022356</td>\n",
              "      <td>-0.048429</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.028440</td>\n",
              "      <td>0.006152</td>\n",
              "      <td>-0.011055</td>\n",
              "      <td>0.041329</td>\n",
              "      <td>0.015947</td>\n",
              "      <td>-0.052161</td>\n",
              "      <td>0.001078</td>\n",
              "      <td>0.011486</td>\n",
              "      <td>22.170000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>139151.000000</td>\n",
              "      <td>1.315186</td>\n",
              "      <td>0.800026</td>\n",
              "      <td>1.024311</td>\n",
              "      <td>0.744782</td>\n",
              "      <td>0.613433</td>\n",
              "      <td>0.395862</td>\n",
              "      <td>0.569151</td>\n",
              "      <td>0.326845</td>\n",
              "      <td>0.603295</td>\n",
              "      <td>...</td>\n",
              "      <td>0.188001</td>\n",
              "      <td>0.530247</td>\n",
              "      <td>0.147524</td>\n",
              "      <td>0.441170</td>\n",
              "      <td>0.350957</td>\n",
              "      <td>0.240191</td>\n",
              "      <td>0.090842</td>\n",
              "      <td>0.078705</td>\n",
              "      <td>77.500000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>172792.000000</td>\n",
              "      <td>2.451888</td>\n",
              "      <td>16.497472</td>\n",
              "      <td>4.187811</td>\n",
              "      <td>16.715537</td>\n",
              "      <td>34.801666</td>\n",
              "      <td>73.301626</td>\n",
              "      <td>120.589494</td>\n",
              "      <td>18.329406</td>\n",
              "      <td>10.392889</td>\n",
              "      <td>...</td>\n",
              "      <td>27.202839</td>\n",
              "      <td>7.357255</td>\n",
              "      <td>19.228169</td>\n",
              "      <td>4.584549</td>\n",
              "      <td>7.519589</td>\n",
              "      <td>3.415636</td>\n",
              "      <td>31.612198</td>\n",
              "      <td>33.847808</td>\n",
              "      <td>25691.160000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows √ó 31 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                Time             V1             V2             V3  \\\n",
              "count  148671.000000  148671.000000  148671.000000  148671.000000   \n",
              "mean    94665.917819       0.001213      -0.003787       0.000954   \n",
              "std     47491.905807       1.952630       1.652412       1.504227   \n",
              "min         1.000000     -56.407510     -72.715728     -48.325589   \n",
              "25%     54063.000000      -0.919470      -0.595982      -0.889173   \n",
              "50%     84637.000000       0.017236       0.064909       0.179942   \n",
              "75%    139151.000000       1.315186       0.800026       1.024311   \n",
              "max    172792.000000       2.451888      16.497472       4.187811   \n",
              "\n",
              "                  V4             V5             V6             V7  \\\n",
              "count  148671.000000  148671.000000  148671.000000  148671.000000   \n",
              "mean        0.000726      -0.000325       0.000314       0.001003   \n",
              "std         1.412236       1.396980       1.342388       1.243926   \n",
              "min        -5.401678    -113.743307     -26.160506     -31.197329   \n",
              "25%        -0.845732      -0.689837      -0.767787      -0.552822   \n",
              "50%        -0.017119      -0.053146      -0.275032       0.039402   \n",
              "75%         0.744782       0.613433       0.395862       0.569151   \n",
              "max        16.715537      34.801666      73.301626     120.589494   \n",
              "\n",
              "                  V8             V9  ...            V21            V22  \\\n",
              "count  148671.000000  148671.000000  ...  148671.000000  148671.000000   \n",
              "mean        0.001141       0.002966  ...       0.002433      -0.000928   \n",
              "std         1.175264       1.096171  ...       0.728833       0.725047   \n",
              "min       -50.943369      -9.481456  ...     -22.757540     -10.933144   \n",
              "25%        -0.208169      -0.640412  ...      -0.227944      -0.543619   \n",
              "50%         0.022356      -0.048429  ...      -0.028440       0.006152   \n",
              "75%         0.326845       0.603295  ...       0.188001       0.530247   \n",
              "max        18.329406      10.392889  ...      27.202839       7.357255   \n",
              "\n",
              "                 V23            V24            V25            V26  \\\n",
              "count  148671.000000  148671.000000  148671.000000  148671.000000   \n",
              "mean       -0.000682       0.000927      -0.000814      -0.000461   \n",
              "std         0.628792       0.605060       0.521639       0.483091   \n",
              "min       -44.807735      -2.836627     -10.295397      -2.534330   \n",
              "25%        -0.161469      -0.353986      -0.317920      -0.327894   \n",
              "50%        -0.011055       0.041329       0.015947      -0.052161   \n",
              "75%         0.147524       0.441170       0.350957       0.240191   \n",
              "max        19.228169       4.584549       7.519589       3.415636   \n",
              "\n",
              "                 V27            V28         Amount          Class  \n",
              "count  148671.000000  148671.000000  148671.000000  148671.000000  \n",
              "mean       -0.001375       0.000457      88.940157       0.001762  \n",
              "std         0.408883       0.334947     255.996600       0.041943  \n",
              "min        -9.895244     -15.430084       0.000000       0.000000  \n",
              "25%        -0.071149      -0.052876       5.600000       0.000000  \n",
              "50%         0.001078       0.011486      22.170000       0.000000  \n",
              "75%         0.090842       0.078705      77.500000       0.000000  \n",
              "max        31.612198      33.847808   25691.160000       1.000000  \n",
              "\n",
              "[8 rows x 31 columns]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Checking for null values\n",
        "df.isnull().sum().max()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As we can see, we have no columns that contain missing values in our dataset, as indicated above. As for our numeric data, we can already see that we have possible outliers, indicated by min/max values that are distant from the mean or median of the variables. Before checking the outliers, let's see how (un)balanced our dataset is."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0    148409\n",
            "1       262\n",
            "Name: Class, dtype: int64\n",
            "\n",
            "These frauds represent 0.1762% of the dataset.\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 504x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Count class values\n",
        "print(df.Class.value_counts())\n",
        "\n",
        "# How much %? Does it match the number stated by the provider?\n",
        "print('\\nThese frauds represent {:.4f}% of the dataset.\\n'.format((df[df.Class == 1].shape[0] / df.shape[0]) * 100))\n",
        "\n",
        "# Plotting barplot\n",
        "fig, ax = plt.subplots(figsize=(7,5))\n",
        "sns.barplot(x=df.Class.unique(), y=df.Class.value_counts(), data=df, ax=ax)\n",
        "ax.set_title('Class distribution', fontsize=12, weight='bold')\n",
        "ax = plt.gca()\n",
        "ax.set_ylim([0, 160000])\n",
        "ax.bar_label(ax.containers[0]);\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "Abordar t√≥picos/informa√ß√µes como:\n",
        "\n",
        "* Plotar os seguintes histogramas:\n",
        "    * Vari√°vel `Time`\n",
        "        * Fraude (`Class == 1`)\n",
        "        * Normal (`Class == 0`)\n",
        "    * Vari√°vel `Amount`\n",
        "        * Fraude (`Class == 1`)\n",
        "        * Normal (`Class == 0`)\n",
        "* Plotar um `boxplot` para a vari√°vel `Amount` quando houve fraude (`Class == 1`)\n",
        "* Plotar uma matriz de correla√ß√£o"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULe7z0jZt0EH"
      },
      "source": [
        "## Prepara√ß√£o dos Dados\n",
        "\n",
        "* Normalizar os dados que ainda n√£o haviam sido pr√©-processados (`Time` e `Amount`)\n",
        "* Dividir o conjunto de dados entre treino e valida√ß√£o\n",
        "* [*Recomendado*] Balancear o conjunto de dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IqfjG_SUSTi-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJNH5qcjRxfX"
      },
      "source": [
        "## Modelo de Machine Learning\n",
        "\n",
        "* Construir um modelo para **classifica√ß√£o**.\n",
        "* [*Opcional*] Construir mais de um modelo para avaliar os desempenhos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lDySx8XUSMw_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3e4ENOTYSUXi"
      },
      "source": [
        "## Avaliar o desempenho do modelo\n",
        "\n",
        "* Identificar a melhor m√©trica para esse tipo de modelo\n",
        "* [*Opcional*] Comparar o desempenho entre diversos modelos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H1jEi7gkSe2r"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Bj7zRZMSfO7"
      },
      "source": [
        "## Conclus√£o\n",
        "\n",
        "* Escrever suas conclus√µes a respeito da constru√ß√£o do modelo"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "[Template] Detec√ß√£o de Fraude em Cart√µes de Cr√©dito.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "1d3566b98539942dfe42f243b655841af5c597145eebc5638a47e844e4435e63"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
